#pragma once

// @generated by torchgen/gen.py from FunctionalInverses.h

#include <ATen/Tensor.h>

namespace at {
namespace functionalization {

struct FunctionalInverses {

static at::Tensor _fw_primal_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t level);
static at::Tensor _make_dual_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, const at::Tensor & tangent, int64_t level);
static at::Tensor view_as_real_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor view_as_complex_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor _conj_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor _neg_view_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor as_strided_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, at::IntArrayRef size, at::IntArrayRef stride, c10::optional<int64_t> storage_offset);
static at::Tensor _sparse_broadcast_to_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, at::IntArrayRef size);
static at::Tensor diagonal_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t offset, int64_t dim1, int64_t dim2);
static at::Tensor expand_copy_SymInt_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, c10::SymIntArrayRef size, bool implicit);
static at::Tensor expand_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, at::IntArrayRef size, bool implicit);
static at::Tensor permute_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, at::IntArrayRef dims);
static at::Tensor _reshape_alias_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, at::IntArrayRef size, at::IntArrayRef stride);
static at::Tensor select_copy_int_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t dim, int64_t index);
static at::Tensor detach_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor slice_copy_Tensor_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t dim, c10::optional<int64_t> start, c10::optional<int64_t> end, int64_t step);
static at::Tensor split_copy_Tensor_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t mutated_view_idx, int64_t split_size, int64_t dim);
static at::Tensor split_with_sizes_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t mutated_view_idx, at::IntArrayRef split_sizes, int64_t dim);
static at::Tensor squeeze_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor squeeze_copy_dim_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t dim);
static at::Tensor t_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor transpose_copy_int_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t dim0, int64_t dim1);
static at::Tensor unsqueeze_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t dim);
static at::Tensor _indices_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor _values_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor indices_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor values_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor crow_indices_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor col_indices_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor ccol_indices_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor row_indices_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);
static at::Tensor unbind_copy_int_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t mutated_view_idx, int64_t dim);
static at::Tensor view_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, at::IntArrayRef size);
static at::Tensor view_copy_dtype_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, at::ScalarType dtype);
static at::Tensor unfold_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views, int64_t dimension, int64_t size, int64_t step);
static at::Tensor alias_copy_inverse(const at::Tensor & base, const at::Tensor & mutated_view, bool reapply_views);

};
}
}
